version: "3"

services:
  llm-engine:
    volumes:
      - ./volumes/engine:/root/.ollama
    container_name: llm-engine
    pull_policy: always
    tty: true
    restart: unless-stopped
    image: llm-engine:latest

  llm-web:
    image: llm-web:latest
    container_name: llm-web
    volumes:
      - ./volumes/web:/app/backend/data
    depends_on:
      - llm-engine
    ports:
      - 443:8080
    environment:
      - 'OLLAMA_BASE_URL=http://ollama:11434'
      - 'WEBUI_SECRET_KEY='
    restart: unless-stopped
    # extra_hosts:
    #   - host.docker.internal:host-gateway
